{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The following code is used to perfom EDA , conversion of string to numerical values and doing encoding for categorical columns."
      ],
      "metadata": {
        "id": "PoQgnlkcZMP4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAhL9cwIFOfm",
        "outputId": "5b541c8b-371b-47de-c7eb-157fd463880b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                    cnt   R-squared:                       1.000\n",
            "Model:                            OLS   Adj. R-squared:                  1.000\n",
            "Method:                 Least Squares   F-statistic:                 8.552e+31\n",
            "Date:                Thu, 02 May 2024   Prob (F-statistic):               0.00\n",
            "Time:                        08:22:36   Log-Likelihood:                 14829.\n",
            "No. Observations:                 584   AIC:                        -2.965e+04\n",
            "Df Residuals:                     578   BIC:                        -2.962e+04\n",
            "Df Model:                           5                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const       3.126e-12    3.3e-13      9.484      0.000    2.48e-12    3.77e-12\n",
            "instant     -2.72e-15   6.28e-16     -4.333      0.000   -3.95e-15   -1.49e-15\n",
            "holiday    -1.364e-12   5.44e-13     -2.508      0.012   -2.43e-12   -2.96e-13\n",
            "atemp      -2.167e-13   1.65e-14    -13.114      0.000   -2.49e-13   -1.84e-13\n",
            "casual         1.0000   1.69e-16   5.93e+15      0.000       1.000       1.000\n",
            "registered     1.0000   9.94e-17   1.01e+16      0.000       1.000       1.000\n",
            "==============================================================================\n",
            "Omnibus:                        5.108   Durbin-Watson:                   1.032\n",
            "Prob(Omnibus):                  0.078   Jarque-Bera (JB):                3.702\n",
            "Skew:                           0.034   Prob(JB):                        0.157\n",
            "Kurtosis:                       2.616   Cond. No.                     2.39e+04\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The condition number is large, 2.39e+04. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv('day.csv')\n",
        "\n",
        "#EDA steps  : -\n",
        "\n",
        "# Convert numeric values with specific labels into categorical string values\n",
        "df['season'] = df['season'].astype(str).replace({'1': 'spring', '2': 'summer', '3': 'fall', '4': 'winter'})\n",
        "# Similarly, convert other numeric columns as required\n",
        "\n",
        "# Perform one-hot encoding for categorical columns\n",
        "df = pd.get_dummies(df, columns=['season', 'weathersit'])  # Adjust columns as needed\n",
        "\n",
        "# Define features (X) and target variable (y)\n",
        "X = df.drop(['cnt', 'dteday'], axis=1)  # Drop 'cnt' and 'dteday' as we can't use them as features\n",
        "y = df['cnt']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Fit scaler to training data and transform training and testing data\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize RFE\n",
        "model = LinearRegression()\n",
        "rfe = RFE(model, n_features_to_select=5)  # Select top 5 features\n",
        "rfe = rfe.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Creating X_train dataframe with RFE selected variables\n",
        "X_train_rfe = X_train.loc[:, rfe.support_]\n",
        "X_train_rfe = sm.add_constant(X_train_rfe)\n",
        "\n",
        "# Running the linear model with statsmodels\n",
        "lm = sm.OLS(y_train, X_train_rfe).fit()\n",
        "\n",
        "# Let's see the summary of our linear model\n",
        "print(lm.summary())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iyG8kDelZK-A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code will calculate VIF and perform Residual Analysis and  Make predictions ."
      ],
      "metadata": {
        "id": "VQ6AbHzRZhPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv('day.csv')\n",
        "\n",
        "# Map categorical variables to numerical values\n",
        "season_map = {1: 'spring', 2: 'summer', 3: 'fall', 4: 'winter'}\n",
        "weather_map = {1: 'clear', 2: 'misty', 3: 'light rain/snow', 4: 'heavy rain/snow'}\n",
        "df['season'] = df['season'].map(season_map)\n",
        "df['weathersit'] = df['weathersit'].map(weather_map)\n",
        "\n",
        "# Create dummy variables for categorical columns\n",
        "df = pd.get_dummies(df, columns=['season', 'weathersit'], drop_first=True)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "df_train, df_test = train_test_split(df, train_size=0.7, test_size=0.3, random_state=100)\n",
        "\n",
        "# Apply MinMax scaling to numeric columns\n",
        "scaler = MinMaxScaler()\n",
        "num_vars = ['temp', 'atemp', 'hum', 'windspeed', 'casual', 'registered', 'cnt']\n",
        "df_train[num_vars] = scaler.fit_transform(df_train[num_vars])\n",
        "\n",
        "# Divide into X and Y sets for model building\n",
        "y_train = df_train.pop('cnt')\n",
        "X_train = df_train\n",
        "\n",
        "# Drop the 'dteday' column\n",
        "X_train = X_train.drop('dteday', axis=1)\n",
        "\n",
        "# Running RFE with 10 variables\n",
        "lm = LinearRegression()\n",
        "\n",
        "# Running RFE with the output number of the variable equal to 10\n",
        "rfe = RFE(lm)\n",
        "rfe = rfe.fit(X_train, y_train)\n",
        "\n",
        "# Selecting the columns supported by RFE\n",
        "col = X_train.columns[rfe.support_]\n",
        "\n",
        "# Building the model using statsmodels\n",
        "X_train_rfe = X_train[col]\n",
        "X_train_rfe = sm.add_constant(X_train_rfe)\n",
        "\n",
        "\n",
        "X_train_rfe = X_train_rfe.apply(pd.to_numeric)\n",
        "\n",
        "X_train_rfe = sm.add_constant(X_train_rfe)\n",
        "\n",
        "\n",
        "print(X_train_rfe.dtypes)\n",
        "\n",
        "# Convert non-numeric columns to numeric data types\n",
        "X_train_rfe = X_train_rfe.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Drop rows with missing values\n",
        "X_train_rfe = X_train_rfe.dropna()\n",
        "\n",
        "# Add constant variable\n",
        "X_train_rfe = sm.add_constant(X_train_rfe)\n",
        "\n",
        "\n",
        "lm = sm.OLS(y_train, X_train_rfe).fit()\n",
        "\n",
        "# Print the summary of the model\n",
        "print(lm.summary())\n",
        "\n",
        "# Drop insignificant variables based on p-values\n",
        "X_train_new = X_train_rfe.drop(['holiday', 'weekday', 'workingday', 'season_summer', 'season_fall'], axis=1)\n",
        "\n",
        "# Rebuild the model without insignificant variables\n",
        "X_train_lm = sm.add_constant(X_train_new)\n",
        "lm = sm.OLS(y_train, X_train_lm).fit()\n",
        "\n",
        "# Print the summary of the updated model\n",
        "print(lm.summary())\n",
        "\n",
        "# Drop the constant column\n",
        "X_train_new.drop(['const'], axis=1, inplace=True)\n",
        "\n",
        "# Calculate VIF for the new model\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "vif = pd.DataFrame()\n",
        "X = X_train_new\n",
        "vif['Features'] = X.columns\n",
        "vif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "print(vif)\n",
        "\n",
        "# Residual Analysis\n",
        "y_train_price = lm.predict(X_train_lm)\n",
        "residuals = y_train - y_train_price\n",
        "sns.distplot(residuals)\n",
        "\n",
        "# Apply scaling to test data\n",
        "df_test[num_vars] = scaler.transform(df_test[num_vars])\n",
        "\n",
        "# Divide into X_test and y_test\n",
        "y_test = df_test.pop('cnt')\n",
        "X_test = df_test\n",
        "\n",
        "# Create X_test_new dataframe with selected columns\n",
        "X_test_new = X_test[X_train_new.columns]\n",
        "X_test_new = sm.add_constant(X_test_new)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = lm.predict(X_test_new)\n",
        "\n",
        "# Model Evaluation\n",
        "plt.scatter(y_test, y_pred)\n",
        "plt.xlabel('Actual Count')\n",
        "plt.ylabel('Predicted Count')\n",
        "plt.title('Actual Count vs Predicted Count')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "KinhhBxRTVQy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}